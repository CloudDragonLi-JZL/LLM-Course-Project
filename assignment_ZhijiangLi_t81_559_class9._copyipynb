{"cells":[{"cell_type":"markdown","metadata":{"id":"XKzF6dMaiLyP"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"YDTXd8-Lmp8Q"},"source":["# T81-559: Applications of Generative AI\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 9 Assignment: MultiModal Models**\n","\n","**Student Name: Your Name**"]},{"cell_type":"markdown","metadata":{"id":"ncNrAEpzmp8S"},"source":["# Google CoLab Instructions\n","\n","If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fU9UhAxTmp8S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743128959227,"user_tz":-480,"elapsed":42810,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"ea411498-d4ed-478a-fcc6-5f1a5b8a1ead"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n","Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\n","  Downloading langchain_core-0.3.49-py3-none-any.whl.metadata (5.9 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n","Downloading langchain_openai-0.3.11-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.49-py3-none-any.whl (420 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.1/420.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.47\n","    Uninstalling langchain-core-0.3.47:\n","      Successfully uninstalled langchain-core-0.3.47\n","Successfully installed langchain-core-0.3.49 langchain_openai-0.3.11 tiktoken-0.9.0\n"]}],"source":["import os\n","\n","try:\n","  from google.colab import drive, userdata\n","  drive.mount('/content/drive', force_remount=True)\n","  COLAB = True\n","  print(\"Note: using Google CoLab\")\n","except:\n","  print(\"Note: not using Google CoLab\")\n","  COLAB = False\n","\n","# Assignment Submission Key - Was sent you first week of class.\n","# If you are in both classes, this is the same key.\n","if COLAB:\n","  # For Colab, add to your \"Secrets\" (key icon at the left)\n","  key = userdata.get('T81_559_KEY')\n","else:\n","  # If not colab, enter your key here, or use an environment variable.\n","  # (this is only an example key, use yours)\n","  key = \"\"\n","\n","# OpenAI Secrets\n","if COLAB:\n","    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","\n","# Install needed libraries in CoLab\n","if COLAB:\n","    !pip install langchain openai langchain_openai"]},{"cell_type":"markdown","metadata":{"id":"QSKZqD1Mmp-C"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7F2MhA7bjag8"},"outputs":[],"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","import PIL\n","import PIL.Image\n","import io\n","from typing import List, Union\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - List of pandas dataframes or images.\n","# key - Your student key that was emailed to you.\n","# course - The course that you are in, currently t81-558 or t81-559.\n","# no - The assignment class number, should be 1 through 10.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","\n","def submit(\n","    data: List[Union[pd.DataFrame, PIL.Image.Image]],\n","    key: str,\n","    course: str,\n","    no: int,\n","    source_file: str = None\n",") -> None:\n","    if source_file is None and '__file__' not in globals():\n","        raise Exception(\"Must specify a filename when in a Jupyter notebook.\")\n","    if source_file is None:\n","        source_file = __file__\n","\n","    suffix = f'_class{no}'\n","    if suffix not in source_file:\n","        raise Exception(f\"{suffix} must be part of the filename.\")\n","\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb', '.py']:\n","        raise Exception(f\"Source file is {ext}; must be .py or .ipynb\")\n","\n","    with open(source_file, \"rb\") as file:\n","        encoded_python = base64.b64encode(file.read()).decode('ascii')\n","\n","    payload = []\n","    for item in data:\n","        if isinstance(item, PIL.Image.Image):\n","            buffered = io.BytesIO()\n","            item.save(buffered, format=\"PNG\")\n","            payload.append({'PNG': base64.b64encode(buffered.getvalue()).decode('ascii')})\n","        elif isinstance(item, pd.DataFrame):\n","            payload.append({'CSV': base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n","        else:\n","            raise ValueError(f\"Unsupported data type: {type(item)}\")\n","\n","    response = requests.post(\n","        \"https://api.heatonresearch.com/wu/submit\",\n","        headers={'x-api-key': key},\n","        json={\n","            'payload': payload,\n","            'assignment': no,\n","            'course': course,\n","            'ext': ext,\n","            'py': encoded_python\n","        }\n","    )\n","\n","    if response.status_code == 200:\n","        print(f\"Success: {response.text}\")\n","    else:\n","        print(f\"Failure: {response.text}\")"]},{"cell_type":"markdown","metadata":{"id":"8fJKkSenqklH"},"source":["# Assignment Instructions\n","\n","For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n","\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg\n","* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg\n","\n","You can see a sample of the WebCam here:\n","\n","![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg)\n","\n","\n","* image - The image number, 1 through 10.\n","* crowded - Is this image crowded with people? (1=yes, 0=no)\n","* cars - Are there cars in this image? (1=yes, 0=no)\n","* bikes - Are there bikes in this image? (1=yes, 0=no)\n","\n","Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n","\n","|image|crowded|cars|bikes|\n","|-|-|-|-|\n","|1|0|0|1\n","|2|0|1|1\n","|3|1|0|0\n","|...|...|...|...|\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qYOvD3M7ofQl"},"source":["### Example MultiModal Code\n","\n","You should use a MultiModal model to obtain the data for each of the 10 images. You should be able to construct a single prompt that gets you the three needed values for each item. I suggest you use the \"gpt-4o-mini\" model with a temperature of 0.1. You will need to develop a prompt that looks for each of the requested values.\n","\n","The following code shows an example of running a MultiModal model with a prompt on the first image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MY3gVyidmp-K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743128988872,"user_tz":-480,"elapsed":8294,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"806834ce-ec56-4eee-c1a7-5ca0b58dbbb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["The image depicts a sunny day at a beach scene, likely at a popular coastal\n","area. In the foreground, there is a path along the beach where people are\n","walking and engaging in various activities. Palm trees line the area, providing\n","a tropical vibe.   To the left, there appears to be some beach equipment and\n","possibly a food stand, indicated by a white canopy. The sandy beach stretches\n","out towards the water, which is visible in the background. A few individuals are\n","seen sitting on benches or walking along the path, and there are some small\n","structures or tents set up nearby. The overall atmosphere looks lively and\n","casual, typical of a beach setting.\n"]}],"source":["from langchain_core.messages import HumanMessage\n","from langchain_openai import ChatOpenAI\n","import base64\n","import httpx\n","import textwrap\n","\n","MODEL = \"gpt-4o-mini\"\n","image_url = 'https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg'\n","prompt = \"Describe this image.\"\n","\n","# Initialize the GPT model\n","model = ChatOpenAI(model=\"gpt-4o-mini\")\n","\n","# Fetch image data and encode it in base64\n","image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n","\n","# Create a message with both text and the image\n","message = HumanMessage(\n","    content=[\n","        {\"type\": \"text\", \"text\": prompt},\n","        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}},\n","    ],\n",")\n","\n","# Get response with a modified prompt from GPT\n","response = model.invoke([message])\n","\n","# Wrap the text output to avoid scrolling off the screen in Colab\n","wrapped_output = textwrap.fill(response.content, width=80)\n","print(wrapped_output)"]},{"cell_type":"markdown","metadata":{"id":"p9jQDSkSJ6ei"},"source":[]},{"cell_type":"markdown","metadata":{"id":"lCy_pvDXqYv4"},"source":["### Solution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akNiBZ5X54Fl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743131222351,"user_tz":-480,"elapsed":3378,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"fc807838-2fa7-4271-c508-147571595c5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success: Submitted Assignment 9 (t81-559) for l.zhijiang:\n","You have submitted this assignment 9 times. (this is fine)\n","No errors, warnings, or notes on your data. Rock on! You will probably do well, but no guarantee. :-)\n"]}],"source":["from langchain_core.messages import HumanMessage\n","from langchain_openai import ChatOpenAI\n","import base64\n","import httpx\n","import pandas as pd\n","\n","MODEL = \"gpt-4o-mini\"\n","#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n","\n","# image_url_template = 'https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{}.jpg'\n","\n","# You must identify your source file.  (modify for your local setup)\n","# file=\"/content/drive/My Drive/Colab Notebooks/assignment_solution_t81_559_class9.ipynb\"  # Google CoLab\n","# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_559_deep_learning\\\\assignments\\\\assignment_yourname_t81_559_class9.ipynb'  # Windows\n","# file='/Users/jheaton/projects/t81_559_deep_learning/assignments/assignment_yourname_t81_559_class9.ipynb'  # Mac/Linux\n","\n","file=\"/content/drive/My Drive/Colab Notebooks/assignment_ZhijiangLi_t81_559_class9.ipynb\"\n","\n","## ... continue your code...\n","# image_urls = [\n","#     f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{i}.jpg\"\n","#     for i in range(1, 11)\n","# ]\n","\n","image_urls = [\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg\",\n","    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg\"\n","]\n","\n","\n","prompt = (\n","    \"Is the image crowded with people? Are there any cars? Are there any bikes? \"\n","    \"Answer only in this exact JSON format: \"\n","    '{\"crowded\": 1 or 0, \"cars\": 1 or 0, \"bikes\": 1 or 0}.'\n",")\n","\n","\n","def analyze_image(image_url):\n","    image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n","    message = HumanMessage(content=[\n","        {\"type\": \"text\", \"text\": prompt},\n","        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}},\n","    ])\n","    response = MODEL.invoke([message])\n","    return eval(response.content)\n","\n","\n","results = []\n","for i, url in enumerate(image_urls, start=1):\n","    try:\n","        result = analyze_image(url)\n","        result[\"name\"] = i\n","        results.append(result)\n","    except:\n","        results.append({\"name\": i, \"crowded\": None, \"cars\": None, \"bikes\": None})\n","\n","\n","df = pd.DataFrame(results)\n","df = df[[\"name\", \"crowded\", \"cars\", \"bikes\"]]\n","\n","\n","## Submit assignment\n","\n","submit(source_file=file,data=[df],key=key,course='t81-559',no=9)\n","\n"]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class9.ipynb","timestamp":1743096047676}]},"kernelspec":{"display_name":"Python 3.11 (genai)","language":"python","name":"genai"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}