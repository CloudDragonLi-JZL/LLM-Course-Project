{"cells":[{"cell_type":"markdown","metadata":{"id":"CdL1ZvDepO-X"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"R_pemiL8pO-Y"},"source":["# T81-559: Applications of Generative AI\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/index.html)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 3 Assignment: LLM Text Classification**\n","\n","**Student Name: Your Name**"]},{"cell_type":"markdown","metadata":{"id":"lky4xopspO-Z"},"source":["# Assignment Instructions\n","\n","A [file](https://data.heatonresearch.com/data/t81-559/assignments/jobs.csv) is provided that contains 25 biographies sentences. Sample lines from this file include:\n","\n","|id\t|bio|\n","|---|---|\n","|1\t|Dr. Emily Carter is a dedicated healthcare professional ...|\n","|2\t|Born in a small town in Texas, she developed a fascination ...|\n","|3\t|Alex is a passionate technology enthusiast with a knack ...|\n","|4\t|Born and raised in a small town, she developed a fascination ...|\n","|5\t|Dr. Emily Carter is a dedicated healthcare professional with over... |\n","|...|...|\n","\n","For each of these, classify into the categories of:\n","\n","* doctor\n","* lawyer\n","* teacher\n","* software engineer\n","* astronaut\n","\n","Your output should look like this:\n","\n","|id|job|\n","|---|---|\n","|id\t|job|\n","|1\t|doctor ...|\n","|2\t|lawyer ...|\n","|3\t|lawyer ...|\n","|4\t|doctor ...|\n","|5\t|lawyer ... |\n","|...|...|\n","\n","Use a large language model (LLM) to extract the single word action from each of these sentences.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U4LQZW_SpO-Z"},"source":["# Google CoLab Instructions\n","\n","If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZnCEIEopO-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738835499905,"user_tz":-480,"elapsed":8510,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"c2048578-5fb8-41a0-b05d-a3df4e0dfcf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.32)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n","Collecting langchain-core<0.4.0,>=0.3.32 (from langchain)\n","  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.59.9)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n","Downloading langchain_openai-0.3.3-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.32\n","    Uninstalling langchain-core-0.3.32:\n","      Successfully uninstalled langchain-core-0.3.32\n","Successfully installed langchain-core-0.3.33 langchain_openai-0.3.3 tiktoken-0.8.0\n"]}],"source":["try:\n","  from google.colab import drive, userdata\n","  drive.mount('/content/drive', force_remount=True)\n","  COLAB = True\n","  print(\"Note: using Google CoLab\")\n","except:\n","  print(\"Note: not using Google CoLab\")\n","  COLAB = False\n","\n","# Assignment Submission Key - Was sent you first week of class.\n","# If you are in both classes, this is the same key.\n","if COLAB:\n","  # For Colab, add to your \"Secrets\" (key icon at the left)\n","  key = userdata.get('T81_559_KEY')\n","else:\n","  # If not colab, enter your key here, or use an environment variable.\n","  # (this is only an example key, use yours)\n","  key = \"\"\n","\n","# OpenAI Secrets\n","import os\n","if COLAB:\n","    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","\n","# Install needed libraries in CoLab\n","if COLAB:\n","    !pip install langchain langchain_openai"]},{"cell_type":"markdown","metadata":{"id":"PMLHwV0hpO-a"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozSyLCNtpO-a"},"outputs":[],"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","import PIL\n","import PIL.Image\n","import io\n","from typing import List, Union\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - List of pandas dataframes or images.\n","# key - Your student key that was emailed to you.\n","# course - The course that you are in, currently t81-558 or t81-559.\n","# no - The assignment class number, should be 1 through 10.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","\n","def submit(\n","    data: List[Union[pd.DataFrame, PIL.Image.Image]],\n","    key: str,\n","    course: str,\n","    no: int,\n","    source_file: str = None\n",") -> None:\n","    if source_file is None and '__file__' not in globals():\n","        raise Exception(\"Must specify a filename when in a Jupyter notebook.\")\n","    if source_file is None:\n","        source_file = __file__\n","\n","    suffix = f'_class{no}'\n","    if suffix not in source_file:\n","        raise Exception(f\"{suffix} must be part of the filename.\")\n","\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb', '.py']:\n","        raise Exception(f\"Source file is {ext}; must be .py or .ipynb\")\n","\n","    with open(source_file, \"rb\") as file:\n","        encoded_python = base64.b64encode(file.read()).decode('ascii')\n","\n","    payload = []\n","    for item in data:\n","        if isinstance(item, PIL.Image.Image):\n","            buffered = io.BytesIO()\n","            item.save(buffered, format=\"PNG\")\n","            payload.append({'PNG': base64.b64encode(buffered.getvalue()).decode('ascii')})\n","        elif isinstance(item, pd.DataFrame):\n","            payload.append({'CSV': base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n","        else:\n","            raise ValueError(f\"Unsupported data type: {type(item)}\")\n","\n","    response = requests.post(\n","        \"https://api.heatonresearch.com/wu/submit\",\n","        headers={'x-api-key': key},\n","        json={\n","            'payload': payload,\n","            'assignment': no,\n","            'course': course,\n","            'ext': ext,\n","            'py': encoded_python\n","        }\n","    )\n","\n","    if response.status_code == 200:\n","        print(f\"Success: {response.text}\")\n","    else:\n","        print(f\"Failure: {response.text}\")"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"H7kgvLHspO-a","jupyter":{"outputs_hidden":true}},"source":["# Assignment #3 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZPLGWgkpO-a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738838928152,"user_tz":-480,"elapsed":13043,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"9a28ac3a-b8b8-49b2-8e43-1052a70570f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success: Submitted Assignment 3 (t81-559) for l.zhijiang:\n","You have submitted this assignment 5 times. (this is fine)\n","No errors, warnings, or notes on your data. Rock on! You will probably do well, but no guarantee. :-)\n"]}],"source":["import os\n","import pandas as pd\n","from scipy.stats import zscore\n","import string\n","import time\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.chains import ConversationChain\n","from langchain.chains import LLMChain\n","from langchain.memory import ConversationBufferMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import PromptTemplate\n","from IPython.display import display_markdown\n","\n","# You must identify your source file.  (modify for your local setup)\n","#file=\"/content/drive/My Drive/Colab Notebooks/assignment_yourname_t81_559_class3.ipynb\"  # Google CoLab\n","# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_559_deep_learning\\\\assignments\\\\assignment_yourname_t81_559_class3.ipynb'  # Windows\n","# file='/Users/jheaton/projects/t81_559_deep_learning/assignments/assignment_yourname_t81_559_class3.ipynb'  # Mac/Linux\n","file=\"/content/drive/My Drive/Colab Notebooks/assignment_ZhijiangLi_t81_559_class3.ipynb\"\n","# Begin assignment\n","\n","df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-559/assignments/jobs.csv\")\n","\n","df.head(10)\n","\n","## ... continue your code...\n","MODEL = 'gpt-4o-mini'\n","TEMPERATURE = 0.25\n","TEMPLATE = \"\"\"Classify each biography into one of the following job categories:\n","- doctor\n","- lawyer\n","- teacher\n","- software engineer\n","- astronaut\n","\n","Return only the job title with lower case letters.\n","\n","Biography:\n","{bio}\"\"\"\n","PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"bio\"], template=TEMPLATE)\n","\n","def classify_job(llm, bio):\n","    chain = PROMPT_TEMPLATE | llm\n","    while True:\n","        try:\n","            response = chain.invoke({\"bio\": bio})\n","            return response.content.strip() if hasattr(response, \"content\") else \"unknown\"\n","        except Exception as e:\n","            if \"rate limit\" in str(e).lower():\n","                print(\"Rate limit reached. Retrying in 60 seconds...\")\n","                time.sleep(60)\n","            else:\n","                raise e\n","\n","def process_dataframe(df, llm):\n","    df = df[[\"id\", \"bio\"]]\n","    df[\"job\"] = df[\"bio\"].apply(lambda bio: classify_job(llm, bio))\n","    return df[[\"id\", \"job\"]]\n","\n","\n","llm = start_model()\n","df = process_dataframe(df, llm)\n","# print(df.head(20))\n","\n","df_submit = df\n","\n","\n","## Submit assignment\n","\n","# Submit\n","submit(source_file=file,data=[df_submit],course='t81-559',key=key,no=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWesp8WFUUDc"},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class3.ipynb","timestamp":1738806555162}]},"kernelspec":{"display_name":"Python 3.11 (genai)","language":"python","name":"genai"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}